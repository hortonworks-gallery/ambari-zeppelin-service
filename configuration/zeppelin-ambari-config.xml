<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
 
<configuration>

  <!-- params for service -->
  <property>
    <name>zeppelin.setup.prebuilt</name>
    <value>true</value>
    <description>If true, will download previously built package (instead of building from source). To compile from source instead, set to false.</description>
  </property>

  <property>
    <name>zeppelin.executor.mem</name>
    <value>512m</value>
    <description>Executor memory to use (e.g. 512m or 1g)</description>
  </property> 

  <property>
    <name>zeppelin.executor.instances</name>
    <value>2</value>
    <description>Number of executor instances to use (e.g. 2)</description>
  </property> 


  <!-- <property>
    <name>zeppelin.spark.version</name>
    <value>1.4</value>
    <description>Version of Spark installed in location specified in SPARK_HOME. Default with HDP 2.3.2 is 1.4.1, but can also be set to 1.5 or 1.3 (if you manually installed Spark 1.3 or 1.4)</description>
  </property> -->

  <property>
    <name>zeppelin.spark.jar.dir</name>
    <value>hdfs:///apps/zeppelin</value>
    <description>Shared location where zeppelin spark jar will be copied to. Should be accesible by all cluster nodes</description>
  </property> 
  
  <property>
    <name>zeppelin.install.dir</name>
    <value>/opt</value>
    <description>Local dir where to install component. incubator-zeppelin folder will be created as a subdir of this dir e.g. /opt/incubator-zeppelin</description>
  </property> 

  <property>
    <name>zeppelin.setup.view</name>
    <value>true</value>
    <description>Whether the Zeppelin view should be compiled and sample notebooks downloaded. Set to false if cluster does not have internet access</description>
  </property> 

  <property>
    <name>zeppelin.temp.file</name>
    <value>/tmp/zeppelin.tar.gz</value>
    <description>Temporary file where pre-built package will be downloaded to. If your env has limited space under /tmp, change this to different location. In this case you must ensure that the zeppelin user must be able to write to this location.</description>
  </property>

  <property>
    <name>zeppelin.host.publicname</name>
    <value> </value>
    <description>This is used to setup the Ambari view for Zeppelin. Set this to the public host/IP of zeppelin node (which must must be reachable from your local machine). If installing on sandbox (or local VM), change this to the IP address of VM. 
    If installing on cloud, set this to public name/IP of zeppelin node. Alternatively, if you already have a local hosts file entry for the internal hostname of the zeppelin node (e.g. sandbox.hortonworks.com), you can leave this empty - it will default to internal hostname</description>
  </property>

  <property>
    <name>spark.home</name>
    <value>/usr/hdp/current/spark-client/</value>
    <description>Spark home directory. Defaults to the Spark that comes with HDP (e.g. 1.3.1 with HDP 2.3.0 or 1.4.1 with HDP 2.3.2). To point Zeppelin to different Spark build, change this to location of where you downloaded Spark to (e.g./home/zeppelin/spark-1.5.0-bin-hadoop2.6) </description>
  </property>
  
  <property>
    <name>zeppelin.install_python_packages</name>
    <value>false</value>
    <description>(Optional) (CentOS only) Whether to install python packages for pyspark. Installs numpy scipy pandas scikit-learn</description>
  </property>
  
    
</configuration>  
